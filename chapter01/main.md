# 01. Decisions Under Risk: Probability and Expectation

ポーカーをプレイする理由は、プレイヤーの数だけあります。ある人は社会的な理由で、グループの一員であることを感じたり、ある人はレクリエーションで、ただ楽しむためにプレイします。ある人は、競争を楽しむためにプレイする人もいます。さらに他の人は ギャンブル依存症を解消するため、あるいは人生の他の苦しみをごまかすためにプレイしている人もいます。このような理由に対して 数学的アプローチをとることの難しさのひとつは、楽しむことや帰属意識の価値を数値化することが難しいということです。

ポーカーをプレイする理由は漠然としていて定量化が難しいですが、それに加えて、ゲームそのものにはない金銭的なインセンティブがあるかもしれません。例えば、World Series of Pokerの優勝者は、多額の優勝賞金に加えて、推薦や出演などによる大金を手にすることができます。

また、ポーカーのテーブルでプレイする人たちにとって、1回でもハンドを失うと心理的な打撃が大きいことがあります。このような考え方は非合理的であると批判されるかもしれませんが、ポーカーをプレイするインセンティブを徹底的に検討する上では、やはり必要なことです。金銭的な報酬に限定して考えても、金銭に対する価値観は非線形です。ほとんどの人にとって、500万ドルは人生を変えるお金であり、500万ドルを追加することの**限界的な価値**ははるかに小さいです。

広い意味では、これらの問題はすべて経済学の[**効用論**](https://ja.wikipedia.org/wiki/%E5%8A%B9%E7%94%A8)に含まれます。効用論者は、個人の好みを定量化し、金銭的インセンティブと非金銭的インセンティブを直接比較できるような枠組みを作ろうとしています。実際、ポーカーをするとき(あるいは、労力のかかることをするとき)、私たちが最大化しようとするのは効用です。しかし、効用論を分析の基礎として用いることは困難であり、各人が独自の効用曲線を持っているため、一般的な分析は非常に困難です。

そこで、本書では効用を考えず、ゲーム内で獲得したお金を効用の代用として用いることにします。第IV部のバンクロール理論では、メタゲームに関する考察を詳しく行い、*破滅のリスク*、*ケリー基準*、*確実性等価*などの概念を紹介します。これらはすべて、主にゲーム外の要因に関係するリスクの尺度です。しかし、明示されている場合を除き、ここではプレイヤーはプレイしているゲームに対して十分な資金を持っていること、そして彼らの唯一の目的は、すべてのポイントで最善の決定を下すことによって、獲得するお金を最大化することであることを前提としています。

ポーカーで獲得する総資金を最大化するには、プレイヤーが自分の決断の**期待値**を最大化することが必要です。しかし、この基本的な概念を合理的に紹介する前に、まずその基礎となる確率の概念を理解しなければなりません。以下の資料はRichard EpsteinのテキストThe Theory of Gambling and Statistical Logic(1967)を引用しています。これは、確率とギャンブルに関する貴重な入門書です。

## 確率

ポーカーでは、ほとんどの場合、結果がまだ確定していない状況で判断が行われます。ディーラーが最初にハンドを配るとき、プレイヤーのカードは、少なくとも観察するまではわかりません。しかし、私たちは他のプレイヤーのハンドの内容をある程度知っています。ゲームのルール上、ハンドの内容は制限されています。例えば、JhThを持っていると、相手がAhJhを持っていることはありません。また デッキの構成は開始前に決まっており、ハンドに関する情報を与えてくれます。

ホールデムのハンドを考えてみましょう。そのハンドにAが2枚含まれる確率はどの程度でしょうか？既に答えは分かっているかもしれませんが、その答えが何を意味するのか考えてみてください。このようなハンドを100万回配ったらどうでしょう？エースのペアは何組になるでしょうか？さらに1000万回配ったらどうでしょう？時間をかけて何度も試行すれば、配られたハンドの総数に対するエースのペアの比率は、ある特定の数字に収束していきます。この数字を確率と定義する。確率は、不確実な事象の可能性を評価する数学的枠組みを提供するものであり、ポーカーにおける意思決定の鍵となるものです。

ある実験(ホールデムカードを配る)で $n$ 回の試行である事象 $x$ が $n_0$ 回発生した場合、 $x$ が発生する確率 $p(x)$ を次のように定義します。

$p(x) = \lim\limits_{n \to \infty}\dfrac{n_0}{n}$ **(1.1)**

ここで、ホールデムの1回のハンドがエースのペアになる確率は、 $\dfrac{1}{221}$ であることが判明しました。もちろん、100億回ハンドを配って、配られたハンドの合計に対するエースのペアの比率を観察することで、これを決定することができます。しかし、これは長く困難な作業です。そこで、この問題をいくつかの要素に分割して考えます。まず、1枚のカードだけを考えてみます。1枚のカードがエースである確率はどのくらいでしょうか？この問題でも、さらに分解することができます。1枚のカードがスペードのエースである確率はどのくらいでしょうか？

この最後の質問には、かなり直接的に答えることができます。次のような仮定を置きます。

- 標準的なデッキには52枚のカードがある
- 標準的なデッキには52枚のカードがあり、各カードが配られる可能性は等しい

このとき，あるカードが選ばれる確率は $\dfrac{1}{52}$ です。Asである確率が $\dfrac{1}{52}$ であれば、どのAである確率もそれぞれ $\dfrac{1}{52}$ です。これは、そのカードがAcである確率、Ahである確率、Adである確率も同じです。デッキには4枚のAがあり、それぞれが $\dfrac{1}{52}$ の確率でそのカードになるのですが、これらの確率を合計すると、次のようになります。

$p(A)=\dfrac{1}{13}$

つまり、AsとAhの両方を満たすカードは存在しません。 $\dfrac{1}{13}$ の確率は、(デッキの中のAの枚数)/(全体の枚数)と等しいことに注意してください。この関係は個々の確率の和と同様に成り立ちます。

### 独立した事象

しかし、いくつかの事象は相互に排他的ではありません。例えば、次の2つの事象を考えてみましょう。

1. ハートである
2. エースである

1枚のカードがハートである確率とエースである確率を計算すると、52枚のカードのうちハートは13枚なので、そのカードがハートである確率は $\dfrac{1}{4}$ です。エースである確率は，先ほどと同じく $\dfrac{1}{13}$ です。しかし，1枚のカードがエースかつハートであることもあり得るので，これらの確率を単純に足すことはできません。
事象間の関係には2種類あります。第一は、互いに影響を及ぼさない事象です。例えば、ナスダックの株価指数の終値と、モナコのカジノのクラップステーブルでその晩に出たサイコロの目は、基本的に無関係な事象であり、どちらも他方に影響を与えないはずです。もし、両方の事象が発生する確率が、それぞれの確率の積と等しい場合、その事象は独立であるといいます。AとBの両方が発生する確率は、AとBの**同時確率**と呼ばれます。

この場合、あるカードがハートとエースの両方である同時確率は、 $\dfrac{1}{13}\cdot\dfrac{1}{4}$ 、つまり $\dfrac{1}{52}$ です。これは、カードがハートであることは、エースである確率に影響しないからです(4つのスートはすべて同じカードの集合のため)。

独立した事象は、どちらかの事象が確率0である場合を除き、相互に排他的ではありません。この例では、デッキのハートの総数は13枚で、エースの総数は4枚です。しかし、これらを足すことで、1枚のカード（ハートのエース）をダブルカウントしていることになります。実際には、ハートが13枚とエースが3枚、あるいは、エースが4枚とハートが12枚です。つまり、このカードがハートかエースである確率は、ハートである確率 $\dfrac{1}{4}$ ＋エースである確率 $\dfrac{1}{13}$ -両方である確率 $\dfrac{1}{52}$ 、つまり $\dfrac{4}{13}$ となります。これは、独立であろうと従属であろうとすべての事象に当てはまります。

### 従属

それに対して、互いに影響を与え合う事象もあります。例えば、野球の試合前に、ある有能な投手が ある有能な投手が9回を投げて無失点に抑える確率は3％とします。一方、チームが試合に勝つ確率は60%です。しかし、その投手のチームが試合に勝ち、その投手がシャットアウト(試合終了まで相手を0点に抑えること)する確率は、明らかに60％×3％ではありません。というのも、ピッチャーがシャットアウトした場合、ピッチャーのチームはほぼ必ず試合に勝つからです。このような事象を従属性と呼びます。また Bが起きればAも起きるという確率です。従属事象でAとBの両方が起こる確率は、Aの確率にBの条件付き確率を掛けたものです。Bが与えられたときのAの条件付き確率が、Aだけの確率と等しい場合、事象は独立です。

これら公式にまとめると、次のような表記になります。  
$p(A \cup B) =$ 「AまたはBが発生する確率」  
$p(A \cap B) =$ 「AとBが発生する確率」  
$p(A | B) =$ 「Bがすでに発生している場合にAが発生する条件付き確率」  

この $∪$ と $∩$ の表記は集合論に由来するもので、正式には「和」と「積」を表します。`or`と`and`と同義です。同様に、 $|$ は「条件付き確率」を表す記号です。

次に、相互に排他的な事象の場合、  
$p(A \cup B) = p(A) + p(B)$ **(1.2)**

独立した事象の場合  
$p(A \cap B) = p(A)p(B)$ **(1.3)**

すべての事象に対して  
$p(A \cup B) = p(A) + p(B) - p(A \cap B)$ **(1.4)**

従属事象の場合  
$p(A \cap B) = p(A)p(B|A)$ **(1.5)**

式1.2は、相互に排他的な事象については、式1.4の特殊なケースに過ぎず、 $P(A \cap B) = 0$ です。同様に、式1.3は、独立した事象については、 $P(B|A)=P(B)$ であり、式1.5の特殊なケースと言えます。さらに、 $P(B|A)=P(B)$ であれば、 $P(A|B)=P(A)$ です。

ここで、本題に戻ります。フルデッキから配られたホールデムカードにAが2枚含まれることはどれくらいの頻度でしょうか？ここで、2つの事象があります。

- A: 1枚目のカードがエースである
- B: 2枚目のカードがエースである

 $p(A) = 1/13$ ，同様に $p(B) = \dfrac{1}{13}$ です。しかし，この2つの事象は従属であり，もし事象Aが起これば(1枚目がエース)、カードがデッキに戻されずに配られるので、事象Bが起こる可能性は低くなります。そこで、1枚目がエースであることを前提に、2枚目がエースである $P(B|A)$ を求めます。エースが3枚残っていて、51枚のカードがありうるので、 $P(B|A)=\dfrac{3}{51}$ 、つまり $\dfrac{1}{17}$ です。

$p(A \cap B) = p(A)p(B|A)$  
$p(A \cap B) = \dfrac{1}{13}\cdot\dfrac{1}{17}$  
$p(A \cap B) = \dfrac{1}{221}$  

確率については、他にもいくつかの簡単な性質を挙げることができます。まず どのような事象も、その確率は0以上1以下です。確率の定義に戻ると、 $n$ 回の試行の結果、事象が $n$ 回以上発生することはなく、 $0$ 回未満になることはありません。確実に起こる事象の確率は $1$ で、決して起こらない事象の確率は $0$ です。ある事象の補集合の確率、つまり、ある事象が発生しない確率は、単純に1からその事象の確率を引いたものです。

まとめると、次のような表記になります。

$p(\bar{A})=$ 'Aが起こらない確率'

$C =$ 'ある事象'  
$I =$ '起こり得ない事象'

とすれば、次のようになります。

任意のAに対して $0 \leq p(A) \leq 1$ **(1.6)**  
$p(C) = 1$ **(1.7)**  
$p(I) = 0$ **(1.8)**  
$p(A) + p(\bar{A})= 1$ **(1.9)**  

式1.9は次のように置き換えられます。  
$p(A) = 1 - p(\bar{A})$ **(1.10)**  

これらの法則を使えば、多くの確率の問題を解くことができます。
確率の問題でよくあるのは、2つのサイコロで6が2回出る確率のような単純なものです。サイコロ2個を振って6が2つ揃う確率は、サイコロの目が独立しているので、確率的には1.3式で表されます。最初のサイコロで6を出す確率を $p(A)$ 、2番目のサイコロで6を出す確率を $p(B)$ とします。$p(A \cap B)$を2つ目のサイコロで6を出す確率とします。すると、

$p(A \cap B) = p(A)p(B)$  
$p(A \cap B) = \dfrac16\cdot\dfrac16$  
$p(A \cap B) = \dfrac1{36}$  

同様に，式1.2を用いて，1人のプレイヤーがAA，KK，QQを持つ確率を求めると，次のようになります。

$p(AA) = \dfrac1{221}$  
$p(KK) = \dfrac1{221}$  
$p(QQ) = \dfrac1{221}$  
$p({AA, KK, QQ}) = p(AA) + p(KK) + p(QQ) = \dfrac3{221}$  

さらに、次のような、より複雑な問題を解くことができます。

スートハンドがフラッシュになる確率はどの程度でしょうか？

フラッシュスートを2枚持っているので、デッキには11枚残っています。3枚のカードはすべてフラッシュスートでなければなりません。つまり、Aは1枚目がフラッシュ、Bは2枚目がフラッシュ、Cは3枚目がフラッシュということになります。最初の2枚のカードがともにフラッシュカードであることを考えると、

$p(A) = \dfrac{11}{50}$ (プレイヤーの手札の山札から2枚のカードが取り除かれた状態)  
$p(A|B)= \dfrac{10}{49}$ (フラッシュカード1枚と合計3枚のカードが取り除かれた状態)  
$p(C|(A \cap B)= \dfrac{9}{48}$ (フラッシュカードが2枚、合計4枚のカードが取り除かれた状態)  

1.5 式を適用すると、次のようになります。
$P(A \cap B) = P(A)P(B|A)$  
$P(A \cap B) = \dfrac{11}{50}\cdot\dfrac{10}{49}$  
$P(A \cap B) = \dfrac{11}{245}$  

$D = (A∩B)$ とすると、再び式1.5が使えます。

$p(D \cap C) = p(D)p(C|D)$  
$p(A \cap B \cap C) = p(A \cap B)p(C|(A \cap B))$  
$p(A \cap B \cap C) = \dfrac{11}{245}\cdot\dfrac9{48}$  
$p(A \cap B \cap C) = \dfrac{33}{3920}$ , あるいは1%弱  

これらの法則は、ほぼすべての状況に適用することができます。これらの特性やルールを使って、1つの事象に対する確率を計算できます。

## 確率分布

単一事象の確率は重要ですが、それだけでは状況を十分に分析できないことがよくあります。むしろ、多くの異なる確率を同時に考慮することが重要である場合が多いです。ある事象がもたらす可能性のある結果とその確率を確率分布として特徴づけることができます。

例えば、公平なコイン投げを考えてみましょう。それぞれの結果は互いに排他的で、確率は $\dfrac12$ です。各結果とその確率を組み合わせて、コイン投げの確率分布を作ることができます。つまり、 $(head, \dfrac12)$ と $(tail, \dfrac12)$ の2つの組があります。(head=表，tail=裏)。

コインフリップの結果の確率分布を $C$ とすると、次のように書くことができます。

$C = \lbrace (head, \dfrac12), (tails, \dfrac12) \rbrace$

同様に、サイコロを振った結果の確率分布 $D$ は、次のようになります。

$D = \lbrace (1,\dfrac16), (2, \dfrac16), (3, \dfrac16), (4, \dfrac16), (5, \dfrac16), (6, \dfrac16) \rbrace$

どのような事象に対しても、起こりうる結果を網羅的かつ相互に排他的に列挙し、それらの結果と対応する確率を対にすることで、離散確率分布が構成できます。

したがって、同じ物理的事象から、異なる確率分布を作ることができます。これは、サイコロの目が奇数か偶数かの分布です。

$D' = \lbrace (odd, \dfrac12), (even, \dfrac12) \rbrace$

ポーカーでは、ほとんどの場合、相手のハンドの中身をとても気にします。しかし，ハンドの内容を1組のカードに絞り込めることはほとんどありません。そこで、相手が持つ可能性のあるハンドと、そのハンドを持つ確率を確率分布で表します。ハンドを見る前の最初の時点では、各プレイヤーのハンドの確率分布は同一です。しかし、プレーが進むにつれて、ハンドのプレイ、自分のハンド、ボード上のカードなどを通して得た新しい情報を取り入れることで、それぞれの可能なハンドの確率を常に精緻に推定することができるようになります。

確率分布の各要素に数値を関連付けることができる場合があります。たとえば、友人があなたと一緒にコイントスをするとします。勝った方が負けた方から\$10もらいます。ここで、コイントスの結果は、先ほどの確率分布に従います。

$C = \lbrace (head, \dfrac12)、(tail, \dfrac12) \rbrace$

コインが等しく表裏がでることが分かっているので、ベットの結果である2番目の確率分布を特定することができます。

$C' = \lbrace (win, \dfrac12), (lose, \dfrac12) \rbrace$

さらに、各結果に数値を関連付けることができます。もし、私たちがフリップに勝ったら相手から\$10もらい、負ければ\$10を支払うとすると、次のようになります。

$B = \lbrace (+10, \dfrac12), (-10, \dfrac12) \rbrace$

確率分布の各結果に数値が対応する場合、その分布の期待値(EV)を求めることができます。これは、各結果の値にその確率を掛け合わせ、すべてを合計したものです。本文中では、「 $X$ の期待値」を表すために $\langle X \rangle$ という表記を使用します。

$\langle B \rangle = \dfrac12\cdot(+10) + \dfrac12\cdot(−10)$  
$\langle B \rangle = 5 + (-5)$  
$\langle B \rangle = 0$

直感的にわかりますが、ある金額で公平にコイントスをすると、半分は勝ち、半分は負けになります。金額は同じなので、平均すると収支は同じになります。また、友人の誘いを断って、まったくコイントスをしない場合のEVも、お金のやりとりがないので $0$ です。

確率分布 $P$ が、 $n$ 個の結果のそれぞれに値 $x_i$ と確率 $p_i$ があるとき、 $P$ の期待値 $\langle P \rangle$ は

$\langle P \rangle = \sum\limits_{i=1}^{n}p_ix_i$  **(1.11)**

ポーカーやその他のギャンブルで勝つための核心は、期待値を最大化するという考え方です。この例では、友人があなたに公正な賭けを申し出ています。平均して、友人と一緒に参加しても、参加を拒否した場合と比較して、良くも悪くもありません。

ここで、友人が別の良い取引を持ちかけてきたとします。相手はまたあなたとフリップしますが、あなたが勝った場合、相手はあなたに\$11を支払いますが、相手が勝った場合、あなたは相手に\$10を支払うだけです。ここでも、参加しない場合のEVはは0です。しかし、このEVは、0にはなりません。勝てば\$11を獲得できますが、負ければ\$10を失います。この新しい賭けに対するあなたの期待値 $B_n$ は、

$\langle B_n \rangle = \dfrac12\cdot(+11) + \dfrac12\cdot(-10)$  
$\langle B_n \rangle = 0.50$

この場合、平均して1回につき50セントの勝ちになります。もちろん、これは勝ちが確定しているわけではなく、どのフリップでも50セントが当たるということはあり得ません。あくまでも この期待値の数字が存在するのは、あくまでも総合的なものです。しかし、こうすることで、平均して50セントの勝率があることになります。

別の例として、同じ友人が次のような取引を持ちかけてきたとしよう。あなたは2つ一組のサイコロを一回振って6ゾロが出れば\$30、それ以外の目が出れば-\$1払います。この提案のEVは次のように計算されます。

$\langle B_d \rangle = \dfrac1{36}\cdot(+30) + \dfrac{35}{36}\cdot(-1)$  
$\langle B_d \rangle = -\dfrac5{36}$

あなたにとってこのベットの価値は、約マイナス14セントです。プレイしない場合のEVは0なので、これは悪い賭けであり、受けるべきではありません。友人に、\$11-\$10のコインフリップの賭けに戻るように言ってください。

期待値の非常に重要な特性は、加法的であることです。つまり、6種類のベットを連続して行った場合のEVは、各ベットの個別のEVの合計となります。ほとんどのギャンブルゲーム、そして人生のほとんどのことは、実はこれと同じようなものです。私たちは、小さなコインをひっくり返したり、サイコロを振ったりして、期待値がプラスのものもあればマイナスのものもあり、絶えず提供されています。サイコロの目やコインではなく、保険や債券が対象になっていることもあります。ラスベガスの無料ドリンクやネオンは、何百万もの小さなコイン投げの積み重ねによって支えられているのです。巧みなポーカープレイヤーは、常に有利な状況を利用することで、この期待値の加法的性質を利用しているのです。

ポーカーで確率分布を使う場合、各ハンドの具体的な確率を省略することがよくあります。これは、各ハンドの相対的な確率が、そのハンドが始まったときの確率から変化していないことを意味します。例えば、非常に弱いプレイヤーのレイズが観測されたとします。タイトなプレイヤーがレイズしており，経験上AA、KK、QQ、AKを持っている場合にのみレイズすることが分かっているとすると、相手の手の分布は次のように表されます。

H = \{AA, KK, QQ, AKs, AKo\}

ここで確率を省略したのは、これらのハンドの相対的な確率が、カードが配られたときの確率と同じであることを意味します。また、$<X>$ 表記を使うことで、以下のような状況にも対応できます。例えば、ポーカーで二人のプレイヤーA,Bが以下のレンジから選んだハンドを持っているとします。

A = \{AA, KK, QQ, JJ, AKo, AKs\}  
B = \{AA,KK,QQ\}

すると、次のようになります。

$\langle A, B \rangle$ : レンジAをレンジBに対してプレイしたときの期待値  
$\langle A, XY|B \rangle$ : レンジBから取ったハンドXYに対して、レンジAをプレイする場合の期待値  
$\langle XY| A, XY|B \rangle$ : レンジAのXYをレンジBのハンドXYに対してプレイする場合の期待値  
$\langle A, B \rangle = p(AA) \langle A, AA|B \rangle + p(KK) \langle A, KK|B \rangle + p(QQ) \langle A,QO| B\rangle ...$ といった具合になります。  

さらに、レンジの要素に対して、いくつかの基本的な算術演算を行うことができます。例えば、あるレンジの結果のすべての値に実数の定数を掛けると、結果のレンジの期待値は、元のレンジの期待値に定数を掛けたものに等しくなります。同様に、レンジの結果の値のそれぞれに定数を加えると、結果のレンジの期待値は、元のレンジの期待値に定数を加えたものに等しくなります。

また、確率を表現する一般的な方法として、オッズについても少し説明しておきましょう。オッズとは、ある事象が起こらない確率と、ある事象が起こる確率の比と定義されます。オッズは、「7対5」「3対2」などのように、任意の基準で表現することができます。オッズが小さいほど事象の可能性が高く、大きいほど事象の可能性が低くなります。相対的な手札の価値は、しばしばこのように表現されます。「そのハンドは7対3の確率でもう一方のハンドに勝つ」といことは、70%の確率で勝つということです。

オッズは通常、確率よりも数学的な計算で使うには厄介です。期待値を得るために結果を簡単に掛け合わせることができないからです。なぜなら、オッズは賭けに対する配当の方法に対応しているからです。確率は、どちらかというと数学的な概念です。数学を利用するギャンブラーは、どちらを使ってもかまいませんが、多くの場合、確率を好みます。確率を期待値に変換するのが簡単であるためです。
